{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.4_ParallelProcessing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mFQ2JNZn8oIm"},"source":["<img src=https://brand.uark.edu/_resources/images/UA_Logo_Horizontal.jpg width=\"400\" height=\"96\">\n","\n","###_Artificial intelligence for image processing and analysis._"]},{"cell_type":"markdown","metadata":{"id":"8g_Y-BQS8vsu"},"source":["# Notebook 2.4 Parallel Processing\n","---\n","##### The purpose of this notebook is introduce how to implement comvolution operations on hardware that allows for parallel processing.\n","##### As previously discussed, the convolution operation is achieved by sliding a kernel across an image. This operation, especially for large images, can take a very long time due to the sliding of the kernel that occurs in _series_ (or one pixel after another).\n","##### Historically, graphical processing units (GPUs) have been often used for rendering computer graphics at very high rates (60 times a second).  Now GPUs are increasingly utilized for convolution operations, because they allow for many mathermatical operations to be done in _parallel_ (or all at the same time).  \n","##### In Google Colab, the use of a GPU is free of charge, and only requires a setting to be changed.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"44Kj2s6vPtIm"},"source":["### Required packages\n","---\n","##### **_Run this code chunk first. If you encounter an error when trying to run code chunks in this notebook, then first try re-running this chunk._**"]},{"cell_type":"code","metadata":{"id":"hq84n-cRL-aP"},"source":["# Import all of the necessary packages\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import imageio as io\n","import torch\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4MKU_ZHYqFL3"},"source":["# Enabling the use of a GPU\n","---\n","##### A GPU is enabled to be used at runtime by selecting\n","> #### Edit > Notebook Settings\n","##### on the top of this page.\n","##### A small window will pop-up, and under\n","> #### Hardware Acceleration\n","##### select \n","> #### GPU.\n","##### Then select\n","> #### Save\n","##### on the bottom of the pop-up window.\n","##### The following code chunk can be run to verify that a GPU has been enabled. This code chunk should run almost immediately. If it does not, the you can reset the notebook by selecting \n","> #### Runtime > Restart Runtime\n","##### and refreshing the page.\n"]},{"cell_type":"code","metadata":{"id":"yHY6sKKpr6YV"},"source":["try:\n","  assert torch.tensor(1).cuda() == 1\n","  print('The GPU has successfully been enabled!')\n","except:\n","  print('The GPU has NOT been enabled.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yx8ru7gYurHU"},"source":["# Utilizing the GPU\n","---\n","##### After enabling the use of a GPU, the time it takes to do a convolution operation can be showcased with the following code chunk."]},{"cell_type":"code","metadata":{"id":"__4SEpIjvN_j"},"source":["# Load red blood cell image from github\n","url = \"https://github.com/aewoessn/outreach-program-2021/blob/main/images/red_blood_cells_small.png?raw=true\"\n","test_image = np.mean(io.imread(url),axis=2) / 255\n","test_image = torch.tensor(test_image).unsqueeze(0).unsqueeze(1).float()\n","\n","# Set up arrays to store time values\n","number_of_filters = 30\n","filter_size = np.zeros(number_of_filters,dtype='int8')\n","cpu_time = np.zeros(number_of_filters)\n","gpu_time = np.zeros(number_of_filters)\n","\n","# Get cpu timing\n","number_of_iterations = 1\n","for j in range(number_of_iterations):\n","  for i in range(number_of_filters):\n","    filter_size[i] = i+1\n","    temp_filter = torch.ones((1,1,filter_size[i],filter_size[i])).float()\n","    start_time = time.time()\n","    filtered_image = torch.nn.functional.conv2d(test_image,temp_filter)\n","    end_time = time.time()\n","    cpu_time[i] += (end_time - start_time)\n","cpu_time /= number_of_iterations\n","\n","# Get gpu timing\n","test_image = test_image.cuda()\n","for j in range(number_of_iterations):\n","  for i in range(number_of_filters):\n","    temp_filter = torch.ones((1,1,filter_size[i],filter_size[i])).float().cuda()\n","    start_time = time.time()\n","    filtered_image = torch.nn.functional.conv2d(test_image,temp_filter)\n","    end_time = time.time()\n","    gpu_time[i] += (end_time - start_time)\n","gpu_time /= number_of_iterations\n","\n","# Plot findings\n","fig = plt.figure(figsize=(10,10))\n","plot1 = plt.plot(filter_size,cpu_time*1000,'r',filter_size,gpu_time*1000,'b')\n","ax1 = fig.gca()\n","xlab = ax1.set_xlabel('Size of filter [pixels]').set_fontsize('x-large')\n","ax1.set_xlim(left=1,right=number_of_filters)\n","ax1.set_xticks((1,5,10,15,20,25,30))\n","ylab = ax1.set_ylabel('Time to execute convolution [miliseconds]').set_fontsize('x-large')\n","legend = ax1.legend(('CPU Time','GPU Time'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lKkMUbANLMhQ"},"source":["# Finishing up\n","---\n","##### **_If you used a GPU and are fininshed with the notebook, please make sure to end your session with Google Colab by selecting:_**\n","> ### Runtime > Manage sessions\n","##### **_A window will pop up and you need to locate the current notebook and select:_**\n","> ### TERMINATE"]}]}