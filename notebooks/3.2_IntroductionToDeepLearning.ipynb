{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.2_IntroductionToDeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFQ2JNZn8oIm"
      },
      "source": [
        "<img src=https://brand.uark.edu/_resources/images/UA_Logo_Horizontal.jpg width=\"400\" height=\"96\">\n",
        "\n",
        "###_Biomedical Image Analysis & Artificial Intelligence_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g_Y-BQS8vsu"
      },
      "source": [
        "# Notebook 3.2 Introduction to Deep Learning\n",
        "---\n",
        "##### The purpose of this notebook is to cover the basics of deep learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Kj2s6vPtIm"
      },
      "source": [
        "### Required packages\n",
        "---\n",
        "##### **_NOTE: This notebook is accelerated with the use of GPU hardware, but is not required. please refer to notebook 2.4_ParallelProcessing if you need a refresher on how to do this._**\n",
        "##### **_Run this code chunk first. If you encounter an error when trying to run code chunks in this notebook, then first try re-running this chunk._**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq84n-cRL-aP"
      },
      "source": [
        "# Import all of the necessary packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFUQxPupuoUi"
      },
      "source": [
        "# Training a model with Deep Learning\n",
        "---\n",
        "##### Training some type of AI model with deep learning is relatively straightforward, but does require a few mathematical tricks. The tricks used in this notebook will not be covered in detail due to being out of the scope of this module, however, the terms used in this notebook can easily be searched to learn more.\n",
        "##### Training a deep learning model can be broken up into 4 steps, and we will go through each of these steps in this notebook:\n",
        "1. Forward pass\n",
        "2. Loss calculation\n",
        "3. Back-propogation\n",
        "4. Gradient descent\n",
        "\n",
        "##### To walk through each step, we will use a common example of a deep learning model, in this case a multi-layer perceptron (_MLP_).  The input is a small image of a handwritten digit and the model predicts what handwriten digit is shown in the image. Here are some of the images that will be used:\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkHH3N4e06nP"
      },
      "source": [
        "# Step 0: Network Initialization\n",
        "---\n",
        "##### Before any network training is done, we must first inspect the dataset, and decide on how our model will be deisgned. \n",
        "##### Each image is 28 by 28 pixels (784 pixels total), which we can treat as our number of _inputs_. The handwritten digits range from 0-9, meaning there are 10 possible digits that we would want to predict, which is the number of _outputs_ that we want. Finally, the rest of the network architecture (the number of layers and number of perceptrons per layer) is very arbitrary, and finding the ideal network attributes ultimately relies on trial and error. For this particular example, we will use 512, 256 and 128 perceptrons for the first, second, and third layer, respectively.\n",
        "\n",
        "<img src=\"https://github.com//aewoessn/outreach-program-2021/blob/main/figures/outreach_mlp.png?raw=true\" alt=\"outreach_mlp.png\" width=\"469.5\" height=\"488\">\n",
        "\n",
        "##### The `torch` package we are using is made for deep learning neural networks.  It comes with convenience functions so we do not have to manually create the network.  As a result, the  code chunk below looks a little different from previous examples. Within the `torch` environment, _layers_ are defined which contain all of the perceptron weights for a layer, which is followed by a layer that specifies the _activation function_. In this example, the _activation function_ is different than what was previous discussed due to specific mathematical requirements. If you are interested, a list of common activation functions, along with how they look plotted, can be found [here](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KbFz1Z1_YUb"
      },
      "source": [
        "# Define network architecture\n",
        "number_of_inputs = 784\n",
        "number_of_layers = 3\n",
        "number_of_perceptrons_per_layer = [512,256,128]\n",
        "number_of_outputs = 10\n",
        "\n",
        "# Generate the network (this will look different than the previous notebook, but is doing the same exact thing)\n",
        "test_model = nn.Sequential(\n",
        "    nn.Flatten(start_dim=1, end_dim=-1),\n",
        "    nn.Linear(number_of_inputs,number_of_perceptrons_per_layer[0]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(number_of_perceptrons_per_layer[0],number_of_perceptrons_per_layer[1]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(number_of_perceptrons_per_layer[1],number_of_perceptrons_per_layer[2]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(number_of_perceptrons_per_layer[2],number_of_outputs)\n",
        ")\n",
        "\n",
        "# Print out message indicating that the network has been created\n",
        "print('The MLP model has successfully been generated!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVf3hY9fHJu_"
      },
      "source": [
        "### Loading the dataset\n",
        "---\n",
        "##### The following code chunk will download the MNIST dataset, but will not store it on your computer. Please note that this may take ~5 minutes to download."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9iqQTvwHV0-"
      },
      "source": [
        "# Load the MNIST digits dataset\n",
        "import os\n",
        "\n",
        "# Check to see if the training file exists...\n",
        "filename = \"/content/MNIST/processed/training.pt\"\n",
        "if not os.path.isfile(filename):\n",
        "  # ...and if it does not, then download it,...\n",
        "  !gdown --id 1jNqLo0LBYrPcGzaDBBA60sqGlclS_nX_\n",
        "\n",
        "  # ...check to see if the destination path exists,...\n",
        "  if not os.path.isdir(\"/content/MNIST/processed/\"):\n",
        "    os.makedirs(\"/content/MNIST/processed/\")\n",
        "\n",
        "  # ...and move the file.\n",
        "  os.rename(\"/content/training.pt\",filename)\n",
        "\n",
        "# Check to see if the test file exists...\n",
        "filename = \"/content/MNIST/processed/test.pt\"\n",
        "if not os.path.isfile(filename):\n",
        "  # ...and ff it does not, then download it,...\n",
        "  !gdown --id 178t2_ul2VvnAHuClPhlE27qHkpE5I8S1\n",
        "\n",
        "  # ...and move the file.\n",
        "  os.rename(\"/content/test.pt\",filename)\n",
        "\n",
        "# Create the dataset\n",
        "mnist_data = torchvision.datasets.MNIST(root='/content/', transform=T.ToTensor())\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3OaJpA3w_54"
      },
      "source": [
        "# Step 1: Forward pass\n",
        "---\n",
        "##### The _forward pass_ step was actually described in the previous notebook as just a weighted summation of all inputs into a single perceptron, and is done for the entire network. Since 10 outputs were specified in the beginning, the outcome of the _forward pass_ is going to be 10 _probabilities_, which are the likelihood that the model thinks that the input image corresponds to every possible digit.\n",
        "##### The output of this code chunk shows the input image, as well as the probability, or percent confidence, that the model is confident that the input image is each digit.  As you can see, an untrained network is not going to know what digit it is looking at."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZn-kDKWIjcK"
      },
      "source": [
        "# Get the first image in the MNIST dataset\n",
        "input_image = mnist_data.data[0,:,:].unsqueeze(0).unsqueeze(0).float() / 255.\n",
        "\n",
        "# Compute the forward pass of the image\n",
        "output = test_model.forward(input_image)\n",
        "\n",
        "# Get the probabilities by passing the output through a softmax\n",
        "prob = torch.softmax(output,1)*100\n",
        "\n",
        "# Show the image\n",
        "fig = plt.Figure()\n",
        "img = plt.imshow(input_image.squeeze(0).squeeze(0))\n",
        "ax = plt.gca()\n",
        "ax.set_title('Input image',fontsize='x-large');\n",
        "plt.show()\n",
        "\n",
        "# Generate a report\n",
        "print('\\nNumber - Probability [%]\\n')\n",
        "for i in range(10):\n",
        "  print(str(i) + '   -    ' + str(prob[0,i].detach().numpy()) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzXOAfOZMTiU"
      },
      "source": [
        "# Step 2: Loss calculation\n",
        "---\n",
        "##### When the network is finished computing the forward pass from an image, we need to see how well or how poor it was at predicting the correct digit. To do this, we use a _loss function_, which penalizes the network based on how off the prediction was.\n",
        "##### For this particular application, we are really assessing if the input image was predicted to be in the correct group or _class_, therefore it is a _classification_ network. Alternatively, a network could also output some meaningful number or numbers, which is called a _regression_ network.\n",
        "##### The loss function that we are going to use for this example is called a _cross-entropy loss_. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj4yFZazPVM6"
      },
      "source": [
        "# Define which loss function we will be using\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get the correct label for the image\n",
        "input_label = mnist_data.targets[0].unsqueeze(0)\n",
        "\n",
        "# Calculate the loss based on the output from the model\n",
        "model_loss = loss(output,input_label)\n",
        "print(\"The numerical loss value is: \" + str(model_loss.detach().numpy()) + \". The lower this value, the better the model is at predicting the correct digit.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o7706QERqAZ"
      },
      "source": [
        "# Step 3: Back-propogation\n",
        "---\n",
        "##### After a loss value has been calculated, we need to adjust the all of the weights within the network so that it can do better later on. The first thing we need to do is calculate how drastically we need to adjust each weight in the network. There is a lot of calculus involved with this step, and this module will not go over these details. However, you should know that this step is called _back-propogation_, since the magnitude of how drastically the weights should be adjusted are propogated backwards through the network, starting with the loss value (output) and ending with the input weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dnUJIBgTfbw"
      },
      "source": [
        "# Back-propogate the loss function through the network\n",
        "model_loss.backward()\n",
        "print('The loss value has been propogated to each weight. Now each weight can be adjusted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsHaWht6TsYX"
      },
      "source": [
        "# Step 4: Gradient descent\n",
        "---\n",
        "##### Now that we have calculated how drastically we want to adjust each weight, we can actually adjust them using what is called a _gradient descent_ algorithm. Gradient descent is a way to step through a function to end up at some area that is a minimum value with respect to the values around it.\n",
        "##### At each step, the amount that we adjust the weight is usually orders of magnitude greater that the amount that we actually want to adjust the weights. To scale the amount that we change the weight, we use a very small _learning rate_.\n",
        "##### A good analogy for gradient descent is to picture a mathematical function, and imagine you place a marble somewhere on the surface. When you let go of the marble, gravity will move the marble to the lowest spot on the function.\n",
        "##### Below is a code chunk that demonstrates gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncu_kBcQU8S9",
        "cellView": "form"
      },
      "source": [
        "#@title --- Hidden code (double-click to show code) ---\n",
        "# Use y = x^2 as an example for gradient descent\n",
        "input = np.arange(-3,3,0.001)\n",
        "output_func = lambda x: x**2\n",
        "output = input**2\n",
        "\n",
        "# Pick a starting point for the 'marble'\n",
        "starting_point = -2.7\n",
        "current_point = starting_point\n",
        "current_slope = (output_func(current_point-0.1) - output_func(current_point+0.1)) / ((current_point-0.1)-(current_point+0.1))\n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "func_line = plt.plot(input,output,zorder=1)\n",
        "point_plot = plt.plot(current_point,output_func(current_point),'ro',markersize=12)\n",
        "ax = plt.gca()\n",
        "ax.set_title(\"Current slope: \" + str(current_slope))\n",
        "ax.set_ylabel('Y = X^2',fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "tol = 1e-4\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "velocity = 0\n",
        "count = 0\n",
        "while np.abs(current_slope) > tol:\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  velocity = ((velocity*momentum) - (learning_rate*current_slope))\n",
        "  current_point += velocity \n",
        "  current_slope = (output_func(current_point-0.1) - output_func(current_point+0.1)) / ((current_point-0.1)-(current_point+0.1))\n",
        "\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "  ax = plt.gca()\n",
        "  func_line = plt.plot(input,output,zorder=1);\n",
        "  point_plot = plt.plot(current_point,output_func(current_point),'ro',markersize=12);\n",
        "\n",
        "  if np.abs(current_slope) > tol:\n",
        "    ax.set_title(\"Current slope: \" + str(current_slope))\n",
        "    ax.set_ylabel('Y = X^2',fontsize='x-large')\n",
        "  else:\n",
        "    ax.set_title(\"Done after \" + str(count) + \" iterations.\")\n",
        "    ax.set_ylabel('Y = X^2',fontsize='x-large')\n",
        "    \n",
        "  plt.show()\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C_ccIUKUHhI"
      },
      "source": [
        "### Implementing Gradient Descent\n",
        "---\n",
        "##### There are few different gradient descent algorithms, but they essentially achieve the same goal. Here is an animation showing a few common algorithms:\n",
        "<img src=\"https://github.com/aewoessn/outreach-program-2021/blob/main/figures/Optimizer.gif?raw=true\" alt=\"Optimizer.gif\" width=\"400\" height=\"320\"><img src=\"https://github.com/aewoessn/outreach-program-2021/blob/main/figures/OptimizerLegend.png?raw=true\" alt=\"OptimizerLegend.png\" width=\"163\" height=\"73\">\n",
        "\n",
        "##### Additionally, weights are randomly generated during network initialization because there could potentially be multiple _local minima_ for a single loss function, where some are better than others. Here is an example of multiple different starting locations all with the same optimizer that end up in different _local minima_.\n",
        "<img src=\"https://github.com/aewoessn/outreach-program-2021/blob/main/figures/LocalMinima.gif?raw=true\" alt=\"LocalMinima.gif\" width=\"400\" height=\"320\">\n",
        "\n",
        "##### Similar to the back-propogation, the `torch` package provides very convenient functions to accomplish this step, as seen in the following code chunk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cq1A6aRXX7s"
      },
      "source": [
        "# Specify the optimizer (or gradient descent algorithm)\n",
        "optimizer = torch.optim.Adam(test_model.parameters())\n",
        "\n",
        "# Gradient descent iteration\n",
        "optimizer.step()\n",
        "print('The network weights have been adjusted for the input image.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6VLsxXaYJyj"
      },
      "source": [
        "### Re-evaluating the model\n",
        "---\n",
        "##### To double check that the model was successfully trained on the image, we can re-evaluate the same image as before.\n",
        "##### The output of this code chunk will show the input image, as well as the confidence of the model for the digit in the image _after backpropogation_.\n",
        "##### The model should be slightly more confident in the correct answer now since we trained the model on the input image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fQqe_esYO4j"
      },
      "source": [
        "# Compute the forward pass of the image\n",
        "output = test_model.forward(input_image)\n",
        "\n",
        "# Get the probabilities by passing the output through a softmax\n",
        "prob = torch.softmax(output,1)*100\n",
        "\n",
        "# Show the image\n",
        "fig = plt.Figure()\n",
        "img = plt.imshow(input_image.squeeze(0).squeeze(0))\n",
        "ax = plt.gca()\n",
        "ax.set_title('Input image',fontsize='x-large');\n",
        "plt.show()\n",
        "\n",
        "# Generate a report\n",
        "print('\\nNumber - Probability [%]\\n')\n",
        "for i in range(10):\n",
        "  print(str(i) + '   -    ' + str(prob[0,i].detach().numpy()) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVVaUQHVY9QV"
      },
      "source": [
        "# Training the model on the whole dataset\n",
        "---\n",
        "##### Now that we have run through a single iteration of training for a single image, we can expand this to train the model over the entire dataset. Training on different digit images will change the weights that we just updated, but over time, the average loss for each digit will decrease, resulting in a model that can correctly predict every digit. \n",
        "##### When training over the entire dataset, the model is said to have completed an _epoch_, or lifetime of the dataset. At this point, we re-collect all of the images used for training, and continue to train the model. We can do this for as long as we would like, but **_deep learning models are usually benchmarked to each other based on the accuracy of the model as well as how long it took to train the model._** This concept is good to keep in mind, and will be covered in detail in a few notebooks. For now, we are only interested on training a network with the entire dataset.\n",
        "##### Additionally, training for a very large amount of epochs (>100) can result in diminishing returns or even negatively impact the model.\n",
        "##### In the below code chunk, we combine all of the deep learning steps and train the MLP model end-to-end. **_Whether you use a GPU or not, this should only take a few minutes._**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2id6Hj2aa0py",
        "cellView": "form"
      },
      "source": [
        "#@title --- Hidden code (double-click to show code) ---\n",
        "\n",
        "# Give some context of what is going on\n",
        "print('Preparing the network and dataset...')\n",
        "\n",
        "# Define network architecture\n",
        "number_of_inputs = 784\n",
        "number_of_layers = 3\n",
        "number_of_perceptrons_per_layer = [512,256,128]\n",
        "number_of_outputs = 10\n",
        "\n",
        "# Generate the network (this will look different than the previous notebook, but is doing the same exact thing)\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(start_dim=1, end_dim=-1),\n",
        "    nn.Linear(number_of_inputs,number_of_perceptrons_per_layer[0]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(number_of_perceptrons_per_layer[0],number_of_perceptrons_per_layer[1]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(number_of_perceptrons_per_layer[1],number_of_perceptrons_per_layer[2]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(number_of_perceptrons_per_layer[2],number_of_outputs)\n",
        ")\n",
        "\n",
        "try:\n",
        "  model = model.cuda()\n",
        "  canUseGPU = True\n",
        "except:\n",
        "  print('Warning: The GPU has not been enabled. Training may take longer than expected.')\n",
        "  canUseGPU = False\n",
        "\n",
        "# Load the MNIST digits dataset\n",
        "batchsize = 10\n",
        "data_loader = torch.utils.data.DataLoader(mnist_data,batch_size=batchsize,shuffle=True)\n",
        "\n",
        "# Specify the number of epochs\n",
        "number_of_epochs = 3\n",
        "\n",
        "# Pull out a small subset of the dataset that will be used to benchmarking purposes\n",
        "test_images = mnist_data.data[[1,3,5,7,9,0,13,15,17,4],:,:].float().unsqueeze(1) / 255.\n",
        "\n",
        "if canUseGPU:\n",
        "  test_images = test_images.cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  test_output = model.forward(test_images).cpu()\n",
        "  test_prob = torch.transpose(torch.softmax(test_output,1)*100,0,1)\n",
        "\n",
        "print('...Done')\n",
        "\n",
        "# Plot the results\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "plt.imshow(test_prob)\n",
        "ax = plt.gca()\n",
        "plt.xticks([])\n",
        "secax = ax.secondary_xaxis('top')\n",
        "secax.set_xticks(np.arange(0,10))\n",
        "secax.set_xlabel('Predicted digit',fontsize='x-large')\n",
        "plt.yticks(np.arange(0,10))\n",
        "ax.set_ylabel('Actual digit',fontsize='x-large')\n",
        "plt.clim(0,100)\n",
        "cbar = plt.colorbar()\n",
        "cbar.set_label('Confidence in prediction [%]',fontsize='x-large')\n",
        "plt.title('Output from epoch: 0 of ' + str(number_of_epochs),fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "# Define which loss function we will be using\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Specify the optimizer (or gradient descent algorithm)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Go through each epoch\n",
        "for ep in range(number_of_epochs):\n",
        "\n",
        "  # Set up a progress bar for training\n",
        "  with tqdm(total=len(mnist_data), desc=f'Epoch {ep + 1}/{number_of_epochs}', unit='img') as pbar:\n",
        "    \n",
        "    # Go through all of the images in the dataset\n",
        "    for i, data in enumerate(data_loader, 0):\n",
        "      # Get the current minibatch\n",
        "      inputs, labels = data\n",
        "\n",
        "      if canUseGPU:\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "      # Clear gradients (this is just required)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      output = model.forward(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss_value = loss(output,labels)\n",
        "\n",
        "      # Back-propogate\n",
        "      loss_value.backward()\n",
        "\n",
        "      # Gradient descent\n",
        "      optimizer.step()  \n",
        "\n",
        "      # Update progress bar\n",
        "      pbar.update(batchsize)\n",
        "\n",
        "  # Clear the output\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    test_output = model.forward(test_images).cpu()\n",
        "    test_prob = torch.softmax(test_output,1)*100\n",
        "\n",
        "  # Plot the results\n",
        "  fig = plt.figure(figsize=(10,5))\n",
        "  plt.imshow(test_prob)\n",
        "  ax = plt.gca()\n",
        "  plt.xticks([])\n",
        "  secax = ax.secondary_xaxis('top')\n",
        "  secax.set_xticks(np.arange(0,10))\n",
        "  secax.set_xlabel('Predicted digit',fontsize='x-large')\n",
        "  plt.yticks(np.arange(0,10))\n",
        "  ax.set_ylabel('Actual digit',fontsize='x-large')\n",
        "  plt.clim(0,100)\n",
        "  cbar = plt.colorbar()\n",
        "  cbar.set_label('Confidence in prediction [%]',fontsize='x-large')\n",
        "  plt.title('Output from epoch: '+ str(ep+1) + ' of ' + str(number_of_epochs),fontsize='x-large')\n",
        "  plt.show()\n",
        "\n",
        "# Show each digit in the small test batch and display the digit predicted with the models confidence\n",
        "f = plt.figure(figsize=(15,15))\n",
        "\n",
        "for i in range(10):\n",
        "  f.add_subplot(2,5,i+1)\n",
        "  plt.imshow(test_images[i,:,:].squeeze(0).cpu())\n",
        "  plt.gca().set_title(\"Predicted: \" + str(torch.argmax(test_prob[i,:]).detach().numpy()) + \" (\" + str(torch.max(test_prob[i,:]).detach().numpy()) + \"%)\")\n",
        "f.subplots_adjust(bottom=0.55)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJqsbOsoi_d9"
      },
      "source": [
        "# Trained model analysis\n",
        "---\n",
        "##### To motivate the next topic, we can map the average weight for each pixel in the input image, as shown in the following code chunk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoSmomF9hR0m"
      },
      "source": [
        "# Pull out the first set of weights\n",
        "count = 0\n",
        "for params in model.parameters():\n",
        "  if count == 0:\n",
        "    weight = params.cpu().detach()\n",
        "  count += 1\n",
        "\n",
        "# Get the average weight for each pixel in the input image\n",
        "sum_weight = torch.sum(torch.abs(weight),dim=0)\n",
        "img_weight = torch.reshape(sum_weight,(28,28))\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img_weight);\n",
        "plt.gca().set_title('Summed weights for each pixel of the input image')\n",
        "cbar = plt.colorbar(shrink=0.8);\n",
        "cbar.set_label('Sum of all weights at each pixel',fontsize='x-large')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofKJHTVXj8d0"
      },
      "source": [
        "### Interpreting results\n",
        "---\n",
        "##### By looking at a map of the average weights for the input image, we see that most of the pixels toward the center of the input image are non-zero. More interestingly, the pixels toward the corners of the input image are very close to zero.\n",
        "##### Suppose some of our digits are not centered in the image... \n",
        "1. Do you think we would get different results? \n",
        "2. How do you think we can get around this issue?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKkMUbANLMhQ"
      },
      "source": [
        "# Finishing up\n",
        "---\n",
        "##### **_If you used a GPU and are fininshed with the notebook, please make sure to end your session with Google Colab by selecting:_**\n",
        "> ### Runtime > Manage sessions\n",
        "##### **_A window will pop up and you need to locate the current notebook and select:_**\n",
        "> ### TERMINATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08iydcfdhNMA"
      },
      "source": [
        "# Ready for the next notebook?\n",
        "---\n",
        "##### You can click [here](https://colab.research.google.com/github/aewoessn/outreach-program-2021/blob/main/notebooks/3.3_ConvolutionalNeuralNetworks.ipynb) to take you to the next notebook."
      ]
    }
  ]
}